{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "\n",
    "### Input Layer:\n",
    "\n",
    "The input layer represents the data (source dataset) used to predict or generate desired outputs of an artificial neural network.  In practice this the input layer will accept rows or vectors of numerical or numerically encoded values.\n",
    "\n",
    "### Hidden Layer:\n",
    "\n",
    "A hidden layer is a set or vector of interim values that are the result of a numerical transformation of the values in our input layer. A neural network can zero or more hidden layers as input data is transformed to a set of output data values.  Hidden layers can't be accessed or manipulated directly - only through the application of the network's numerical transformations.\n",
    "\n",
    "### Output Layer:\n",
    "\n",
    "The output layer contains the results of the network process transforming inputs through the layers of the network.  \n",
    "\n",
    "### Neuron:\n",
    "\n",
    "A neuron is a node in the network that contains a numerical value.  It is the result of a transformation of a set of inputs or node values from a previous hidden layer in the network.  The transformation is typically a sum of weighted input values in addition to a bias value that is subject to an activation function.\n",
    "\n",
    "### Weight:\n",
    "\n",
    "A weight is a factor multiplied to an input in the form of a dataset vector (model input) or an interim node.  It serves as a tuning factor used to transform input data to an output that can be used as a prediction or model result. Weights are adjusted or tuned in order to minimize a cost or loss function.\n",
    "\n",
    "### Activation Function:\n",
    "\n",
    "An activation function is appled to a node's value which has been generated by transforming network inputs or inputs from previous hidden layers in network.  The activation determines whether the node is applicable as a model output or for transformation by the next hidden layer in the network (if applicable)\n",
    "\n",
    "### Node Map:\n",
    "\n",
    "A node map is visual depiction of a neural network that represents how data is transformed from model inputs to model outputs via zero or more hidden layers\n",
    "\n",
    "### Perceptron:\n",
    "\n",
    "A Perceptron is a simple neural network that takes one or more inputs and transforms those inputs as a weighted sum which is applied to an activation function resulting in a model output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXuy9WcWzxa4"
   },
   "source": [
    "## Inputs -> Outputs\n",
    "\n",
    "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlSwIJMC0A8F"
   },
   "source": [
    "In a neural network information flows from a set of inputs and is transformed into a set of outputs.  The transformation algorithm operates in such as to minimize a cost or loss function - usually the calculation of the mean square error between predicted outputs and actual data.\n",
    "\n",
    "The transformation process comes the form of a sum of weighted inputs (sum of products) plus a bias value.  This result is applied to an activation function that determines if the value is applicable to the next step in the process (either a transformation to a subsequent hidden layer or a resultant set of output values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  y\n",
       "0   0   0  1\n",
       "1   1   0  1\n",
       "2   0   1  1\n",
       "3   1   1  0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = { 'x1': [0,1,0,1],\n",
    "         'x2': [0,0,1,1],\n",
    "         'y':  [1,1,1,0]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame.from_dict(data).astype('int')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sgh7VFGwnXGH"
   },
   "outputs": [],
   "source": [
    "# Create a copy of the dataframe\n",
    "df_wrk = df.copy()\n",
    "df_wrk.drop(\"y\", axis=1, inplace=True)\n",
    "\n",
    "# Generate an array of input arrays (an array of virtual data rows)\n",
    "arr_inputs = df_wrk.to_numpy()\n",
    "\n",
    "# Generate an array of outputs (targets)\n",
    "df_wrk = df.copy()\n",
    "df_wrk.drop([\"x1\", \"x2\"], axis=1, inplace=True)\n",
    "\n",
    "arr_outputs = df_wrk.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an initial set of weights to begin network processing\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "random.seed(33)\n",
    "\n",
    "# gen_weights is a function that generates initial weights for our neural network processing\n",
    "def gen_weights():\n",
    "    ret_wgts = []\n",
    "    \n",
    "    for i in range(2):\n",
    "        ret_wgts.append([random.uniform(-1.0, 1.0)])\n",
    "        \n",
    "    return np.array(ret_wgts) \n",
    "\n",
    "# sigmoid is a function that applies an activation (sigmoid) function to a weighted sum\n",
    "def sigmoid(x):\n",
    "    sgmd = 1 / (1 + np.exp(-x))\n",
    "    return sgmd\n",
    "\n",
    "# deriv_sigmoid calculates the derivative of sigmoid at a passed value (rate of change at point x)\n",
    "def deriv_sigmoid(x):\n",
    "    sgmd = sigmoid(x)\n",
    "    dtv  = sgmd * (1 - sgmd)\n",
    "    return dtv\n",
    "\n",
    "# general_activate is a function that applies an activation function to a numeric value\n",
    "def general_activate(val):\n",
    "    ret_arr = []\n",
    "    for v in val:\n",
    "        tmp_val = 0\n",
    "        if v > 0:\n",
    "            tmp_val = 1\n",
    "            \n",
    "        ret_arr.append(v)\n",
    "        \n",
    "    return np.array(ret_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14065685],\n",
       "       [0.26446599]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = gen_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2714412351626475"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = random.uniform(.01, .33)\n",
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning factor\n",
    "r = .25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after training\n",
      "[[0.15237251]\n",
      " [0.15237251]]\n",
      "Output after training\n",
      "[[0.27144124]\n",
      " [0.42381375]\n",
      " [0.42381375]\n",
      " [0.57618625]]\n"
     ]
    }
   ],
   "source": [
    "# Iterate through x instances refining the network weights \n",
    "for iteration in range(50000):\n",
    "    \n",
    "    # Weighted sum of inputs / weights\n",
    "    weighted_sum = np.dot(arr_inputs, weights)\n",
    "    \n",
    "    # Apply the activate function to enable or disable outputs\n",
    "    activated_output = general_activate(weighted_sum + bias)\n",
    "    \n",
    "    # Calculate error\n",
    "    error = arr_outputs - activated_output\n",
    "    \n",
    "    # Calculate weight adjustments\n",
    "    adjustments = error * r \n",
    "    \n",
    "    # Generate adjusted weights\n",
    "    weights += np.dot(arr_inputs.T, adjustments)\n",
    "    \n",
    "print(\"Weights after training\")\n",
    "print(weights)\n",
    "\n",
    "print(\"Output after training\")\n",
    "print(activated_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the diabetes dataset\n",
    "df_dbtes_work = diabetes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  \n",
       "0                     0.627   50  \n",
       "1                     0.351   31  \n",
       "2                     0.672   32  \n",
       "3                     0.167   21  \n",
       "4                     2.288   33  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the outcome column for now\n",
    "df_dbtes_work_x = df_dbtes_work.drop(\"Outcome\", axis=1)\n",
    "df_dbtes_work_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the dataframe data and produce an array of values\n",
    "x_arr = df_dbtes_work_x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pregnancies',\n",
       " 'Glucose',\n",
       " 'BloodPressure',\n",
       " 'SkinThickness',\n",
       " 'Insulin',\n",
       " 'BMI',\n",
       " 'DiabetesPedigreeFunction',\n",
       " 'Age']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "\n",
    "# Grab the dataframe column names\n",
    "feats = list(df_dbtes_work_x.columns)\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.226180</td>\n",
       "      <td>0.607510</td>\n",
       "      <td>0.566438</td>\n",
       "      <td>0.207439</td>\n",
       "      <td>0.094326</td>\n",
       "      <td>0.476790</td>\n",
       "      <td>0.168179</td>\n",
       "      <td>0.204015</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.198210</td>\n",
       "      <td>0.160666</td>\n",
       "      <td>0.158654</td>\n",
       "      <td>0.161134</td>\n",
       "      <td>0.136222</td>\n",
       "      <td>0.117499</td>\n",
       "      <td>0.141473</td>\n",
       "      <td>0.196004</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.497487</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.406855</td>\n",
       "      <td>0.070773</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.587940</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.036052</td>\n",
       "      <td>0.476900</td>\n",
       "      <td>0.125747</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.704774</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.150414</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.234095</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      0.226180    0.607510       0.566438       0.207439    0.094326   \n",
       "std       0.198210    0.160666       0.158654       0.161134    0.136222   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       0.058824    0.497487       0.508197       0.000000    0.000000   \n",
       "50%       0.176471    0.587940       0.590164       0.232323    0.036052   \n",
       "75%       0.352941    0.704774       0.655738       0.323232    0.150414   \n",
       "max       1.000000    1.000000       1.000000       1.000000    1.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean     0.476790                  0.168179    0.204015    0.348958  \n",
       "std      0.117499                  0.141473    0.196004    0.476951  \n",
       "min      0.000000                  0.000000    0.000000    0.000000  \n",
       "25%      0.406855                  0.070773    0.050000    0.000000  \n",
       "50%      0.476900                  0.125747    0.133333    0.000000  \n",
       "75%      0.545455                  0.234095    0.333333    1.000000  \n",
       "max      1.000000                  1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a \"min/max\" scaler object\n",
    "min_max_scaler = MinMaxScaler()\n",
    "# Scale the feature data\n",
    "x_scaled = min_max_scaler.fit_transform(x_arr)\n",
    "# Transform the scaled data into a dataframe\n",
    "df_dbtes_work_x_scaled = pd.DataFrame(x_scaled)\n",
    "\n",
    "# Add original column names\n",
    "df_dbtes_work_x_scaled.columns = feats\n",
    "# Append the original outcome column\n",
    "outcome_column = df_dbtes_work[\"Outcome\"]\n",
    "df_dbtes_work_x_scaled = pd.concat([df_dbtes_work_x_scaled, outcome_column], axis = 1) \n",
    "\n",
    "# Describe the data... confirm the data has been scaled\n",
    "df_dbtes_work_x_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [],
   "source": [
    "##### Update this Class #####\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, niter = 10):\n",
    "        self.niter = niter\n",
    "    \n",
    "    def __sigmoid(self, x):\n",
    "        sgmd = 1 / (1 + np.exp(-x))\n",
    "        return sgmd\n",
    "    \n",
    "    def __sigmoid_derivative(self, x):\n",
    "        sgm = self.__sigmoid(x)\n",
    "        return (sx * (1 - sx))\n",
    "\n",
    "    def fit_model_predict(self, X, y):\n",
    "        \"\"\"Fit training data\n",
    "        X : Training vectors, X.shape : [#samples, #features]\n",
    "        y : Target values, y.shape : [#samples]\n",
    "        \"\"\"\n",
    "        # Randomly Initialize Weights\n",
    "        weights = []\n",
    "        for i in range(X.shape[1]):\n",
    "            weights.append(random.uniform(-.5, .5))\n",
    "\n",
    "        for i in range(self.niter):\n",
    "            #--- Weighted sum of inputs / weights\n",
    "            weighted_sum = np.dot(X, weights)\n",
    "\n",
    "            #--- Activate!\n",
    "            activated_output = self.__sigmoid(weighted_sum)\n",
    "\n",
    "            #--- Cac error\n",
    "            # Determine error between the target outcome and the nodes activated output\n",
    "            error = y - activated_output\n",
    "            # Determine weight adjustments\n",
    "            adjustments = error * self.__sigmoid_derivative(weighted_sum)\n",
    "\n",
    "            # Update the Weights\n",
    "            weights += np.dot(X.T, adjustments)\n",
    "            \n",
    "        return activated_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a numpy array of feature data (X)\n",
    "X = df_dbtes_work_x_scaled.drop(\"Outcome\", axis=1).to_numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_dbtes_work_x_scaled['Outcome'].to_numpy()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Perceptron class\n",
    "prcpt = Perceptron(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999966, 0.99999113, 0.99999871, 0.99999238, 0.99999926,\n",
       "       0.99999505, 0.99997918, 0.99933062, 0.99999983, 0.99998764,\n",
       "       0.99999958, 0.99999979, 0.99999916, 0.99999885, 0.99999915,\n",
       "       0.9982734 , 0.99999994, 0.9999961 , 0.99998424, 0.99999897,\n",
       "       0.99999995, 0.99999838, 0.99999997, 0.99999953, 0.99999994,\n",
       "       0.99999871, 0.99999952, 0.99998921, 0.99999898, 0.99999949,\n",
       "       0.99999876, 0.99999987, 0.99997225, 0.99999617, 0.99999923,\n",
       "       0.99999396, 0.99999925, 0.99999924, 0.99999899, 0.99999963,\n",
       "       0.99999971, 0.99999977, 0.99999852, 1.        , 0.99999721,\n",
       "       0.99999997, 0.99999469, 0.99999395, 0.99999898, 0.97117345,\n",
       "       0.99999522, 0.99996639, 0.99998893, 0.99999996, 0.99999971,\n",
       "       0.99988883, 0.99999991, 0.99999997, 0.99999986, 0.99999917,\n",
       "       0.93940504, 0.99999829, 0.99989389, 0.99999797, 0.99999439,\n",
       "       0.99999758, 0.99999967, 0.99999969, 0.99997939, 0.99999977,\n",
       "       0.99999738, 0.99999897, 0.99999988, 0.99999978, 0.99999775,\n",
       "       0.99924211, 0.99999097, 0.99999914, 0.99975491, 0.99999499,\n",
       "       0.99994668, 0.90771643, 0.99999804, 0.99999301, 0.99999998,\n",
       "       0.99999914, 0.99999959, 0.99999855, 0.99999964, 0.99999462,\n",
       "       0.99987556, 0.99999923, 0.99999965, 0.9999921 , 0.99999954,\n",
       "       0.99999948, 0.99999409, 0.99986447, 0.99998627, 0.99999998,\n",
       "       0.99999976, 0.99999473, 0.99999916, 0.99999198, 0.99999589,\n",
       "       0.99999709, 0.99999973, 0.99999758, 0.99999371, 0.99999949,\n",
       "       0.99999984, 0.99999922, 0.99999828, 0.99998473, 0.99999876,\n",
       "       0.99999956, 0.99999804, 0.99996251, 0.99999284, 0.99999547,\n",
       "       0.99999999, 0.99999884, 0.99999911, 0.99999601, 0.99999788,\n",
       "       0.99999544, 0.99999964, 0.9999977 , 0.99999964, 0.99999578,\n",
       "       0.99999947, 0.99999596, 0.99999974, 0.99999889, 0.99998839,\n",
       "       0.99999665, 0.99999789, 0.99999187, 0.99999899, 0.99999901,\n",
       "       0.99999284, 0.99999966, 0.99999308, 0.99999392, 0.99999935,\n",
       "       0.99996614, 0.99999724, 0.99999841, 0.99999866, 0.99999276,\n",
       "       0.99999986, 0.99998328, 0.99999995, 0.99999996, 0.99999995,\n",
       "       0.99999999, 0.99997665, 0.99999077, 0.99999602, 0.99999996,\n",
       "       0.9999999 , 0.99999923, 0.99999981, 0.99999546, 0.99999951,\n",
       "       0.99999781, 0.99999932, 0.99999611, 0.99999488, 0.99999931,\n",
       "       0.99999745, 0.99999949, 0.99886115, 0.99999865, 0.99998786,\n",
       "       0.99999993, 0.99999436, 1.        , 0.99999967, 0.9999997 ,\n",
       "       0.99999007, 0.99999836, 0.99994125, 0.99995556, 0.99999757,\n",
       "       0.99999991, 0.9999997 , 0.99999996, 0.99999926, 0.99999979,\n",
       "       0.99998066, 0.99999945, 0.99999849, 0.99994043, 0.99995961,\n",
       "       0.99999997, 0.99997144, 0.99999001, 0.99999927, 0.99999846,\n",
       "       0.99999928, 0.99999966, 0.99999617, 0.99998825, 0.99999867,\n",
       "       0.99999747, 0.99999995, 0.99999995, 0.99999651, 0.99999996,\n",
       "       0.99998381, 0.99999998, 0.99999996, 0.99999965, 0.99999962,\n",
       "       0.99999992, 0.99999894, 0.99999878, 0.9999978 , 0.99999619,\n",
       "       0.99999977, 0.99999965, 0.99785834, 0.99999772, 0.99999093,\n",
       "       0.99999856, 0.99999732, 0.99999955, 0.99999998, 0.99999984,\n",
       "       0.99999991, 0.99999991, 0.99999692, 0.99999766, 0.99999365,\n",
       "       0.99999986, 0.99999994, 0.99999999, 0.99999991, 0.99998874,\n",
       "       0.99999291, 0.99999829, 0.99998976, 0.99999347, 0.99999985,\n",
       "       0.99999993, 0.99999621, 0.99999999, 0.9999994 , 0.99999925,\n",
       "       0.99997774, 0.99999883, 0.99999551, 0.99999745, 0.99998878,\n",
       "       0.99999872, 0.99999639, 0.99999676, 0.99999838, 0.99999987,\n",
       "       0.99999966, 0.99954953, 0.99999845, 0.99999905, 0.99999358,\n",
       "       0.99999829, 0.99974784, 0.99999976, 0.99994717, 0.99924408,\n",
       "       0.99999994, 0.99999421, 0.99999489, 0.99999903, 0.9999957 ,\n",
       "       0.99999969, 0.99999289, 0.99999465, 0.99999285, 0.99999224,\n",
       "       0.99999913, 0.99999963, 0.9999997 , 0.99999959, 0.99999405,\n",
       "       0.99999881, 0.99999996, 0.99999995, 0.99996861, 0.99999939,\n",
       "       0.9999995 , 0.99999842, 0.99999993, 0.99999888, 0.999965  ,\n",
       "       0.9999996 , 0.99999935, 0.99999967, 0.99999931, 0.99999141,\n",
       "       0.99981022, 0.99999874, 0.99999917, 0.99999996, 0.99999691,\n",
       "       0.99999972, 0.99999893, 0.99999686, 0.99999907, 0.99999913,\n",
       "       0.99998931, 0.99999948, 0.99999928, 0.99998625, 0.9999997 ,\n",
       "       0.99999822, 0.99999317, 0.99999959, 0.9999992 , 0.99999917,\n",
       "       0.99999486, 0.99999893, 0.99999688, 0.99999991, 0.9999994 ,\n",
       "       0.99999906, 0.99999895, 0.99999962, 0.99999989, 0.99999775,\n",
       "       0.99999802, 0.99998711, 0.99992538, 0.99999474, 0.99998191,\n",
       "       0.99999997, 0.99907352, 0.99999696, 0.99999991, 0.99999991,\n",
       "       0.99999762, 0.9999956 , 0.99996432, 0.99999938, 0.99999538,\n",
       "       0.99999989, 0.99999298, 0.99753885, 0.99998382, 0.99999284,\n",
       "       0.99999886, 0.99999933, 0.99999685, 0.99998682, 0.99999904,\n",
       "       0.99999973, 0.99999779, 0.9999089 , 0.99999893, 0.99999997,\n",
       "       0.99999981, 0.99999735, 0.99999994, 0.99999925, 0.99999969,\n",
       "       0.99999426, 0.99999686, 0.99998458, 0.99999784, 0.99999991,\n",
       "       0.99999999, 0.99997581, 0.99999602, 0.99999743, 0.99999854,\n",
       "       0.99999992, 0.99999729, 0.99999736, 0.99999985, 0.99999996,\n",
       "       0.99999887, 0.99999048, 0.99999094, 0.99999139, 0.99999718,\n",
       "       0.99997816, 0.99999923, 0.99999995, 0.99999961, 0.99999793,\n",
       "       0.99999595, 0.9999999 , 0.99999507, 0.99999427, 0.99999965,\n",
       "       0.99999803, 0.99998888, 0.99999933, 0.99997426, 0.99999991,\n",
       "       0.99998799, 0.99998475, 0.99999988, 0.99999708, 0.99999849,\n",
       "       0.99999817, 0.99999431, 0.99996942, 0.99999976, 0.99999995,\n",
       "       0.99999987, 0.99999915, 0.99999995, 0.99999907, 0.99999918,\n",
       "       0.99999996, 0.99999675, 0.9999999 , 0.99996149, 0.99999726,\n",
       "       0.99999996, 0.99999399, 0.99999935, 0.99999741, 0.99999994,\n",
       "       0.99999996, 0.94438128, 0.99999967, 0.99999997, 0.99999874,\n",
       "       0.99488206, 0.99999589, 0.99999486, 0.99999738, 0.99998913,\n",
       "       0.99977975, 0.99999991, 0.99999904, 0.99998446, 0.99999955,\n",
       "       0.99999999, 0.99999531, 0.99999817, 0.99999699, 0.99999479,\n",
       "       1.        , 0.99999455, 0.99999957, 0.99999828, 0.99999843,\n",
       "       0.99997221, 0.99999777, 0.99999864, 0.99329554, 0.99999621,\n",
       "       0.99999971, 0.99997743, 0.99999621, 0.99999996, 0.99999798,\n",
       "       0.99999647, 0.99992988, 0.99999823, 0.99999729, 0.99999957,\n",
       "       0.99998596, 0.99994048, 0.9999984 , 0.99872748, 0.99999997,\n",
       "       0.99999995, 0.99999951, 0.99999909, 0.99999932, 0.99999181,\n",
       "       0.99999909, 0.99999968, 0.9999976 , 0.99999891, 0.99999941,\n",
       "       0.9999997 , 0.99999983, 0.99998363, 0.99999932, 0.99987181,\n",
       "       0.9999998 , 0.9999997 , 0.99999997, 0.99999491, 0.99999956,\n",
       "       0.99999742, 0.99999933, 0.99999795, 0.99999839, 0.92798504,\n",
       "       0.999998  , 0.99999126, 0.99999486, 0.99999963, 0.99999971,\n",
       "       0.99999938, 0.99999844, 0.99998601, 0.99999651, 0.99999931,\n",
       "       0.99999632, 0.99999996, 0.99999752, 0.99998548, 0.99999453,\n",
       "       0.99999657, 0.99999444, 0.99996922, 0.999982  , 0.99997796,\n",
       "       0.9999995 , 0.99999987, 0.99999943, 0.9999774 , 0.99999801,\n",
       "       0.99998935, 0.99999966, 0.97393048, 0.99999836, 0.99999248,\n",
       "       0.99997764, 0.99997973, 0.99999715, 0.99999833, 0.99998758,\n",
       "       0.99999684, 0.99999942, 0.99999942, 0.99767467, 0.99999408,\n",
       "       0.99947787, 0.99999781, 0.99973477, 0.99999985, 0.99999997,\n",
       "       0.99999955, 0.99999928, 0.99999946, 0.99999963, 0.99999832,\n",
       "       0.99999998, 0.99999997, 0.99999876, 0.99999988, 0.99999999,\n",
       "       0.99999786, 0.99999696, 0.99999724, 0.99999233, 0.99999593,\n",
       "       0.99999799, 0.99999898, 0.99999359, 0.9999996 , 0.99999363,\n",
       "       0.9999976 , 0.99999994, 0.99999836, 0.99999018, 0.99999716,\n",
       "       0.99998118, 0.99999921, 0.99999288, 0.99999956, 0.99999835,\n",
       "       0.99998656, 0.99999935, 0.99999607, 0.99999425, 0.99999987,\n",
       "       0.99999604, 0.9999684 , 0.99999967, 0.99999622, 0.99999998,\n",
       "       0.99999998, 0.99999275, 0.99999773, 0.99999794, 0.9999988 ,\n",
       "       0.99996519, 0.99999805, 0.99998546, 0.99999995, 0.98797104,\n",
       "       0.99999995, 0.99999981, 0.999999  , 0.99998891, 0.99999966,\n",
       "       0.99999992, 0.99999565, 0.99978649, 0.99999956, 0.99992176,\n",
       "       0.99999918, 0.99572038, 0.99999884, 0.99999979, 0.99974439,\n",
       "       0.99999885, 0.99999999, 0.99998098, 0.99999995, 0.99998736,\n",
       "       0.99999101, 0.99999928, 0.99999998, 0.99999955, 0.99999965,\n",
       "       0.99999218, 0.99999943, 0.99994158, 0.99999937, 0.99890549,\n",
       "       0.99999985, 0.99999799, 0.99999998, 0.9999992 , 0.99999194,\n",
       "       0.99999981, 0.99999313, 0.99999901, 0.99999877, 0.99999086,\n",
       "       0.99999302, 0.9999994 , 0.99998492, 0.9999991 , 0.9999779 ,\n",
       "       0.99999666, 0.99999213, 0.99999826, 0.99999967, 0.99998833,\n",
       "       0.99999908, 0.99999831, 0.99999877, 0.99708525, 0.99999815,\n",
       "       0.99999986, 0.99999916, 0.99999959, 0.99999973, 0.9999911 ,\n",
       "       0.99997594, 0.99999716, 0.9999996 , 0.99998202, 0.99999843,\n",
       "       0.99999894, 0.99998725, 0.99999989, 0.99999992, 0.99999946,\n",
       "       0.99999938, 0.99999999, 0.99999999, 0.99999994, 0.99999784,\n",
       "       0.9999997 , 0.99999928, 0.99999726, 0.99999511, 0.99999971,\n",
       "       0.99999961, 0.99998297, 0.99999972, 1.        , 0.99999691,\n",
       "       0.99999966, 0.99999916, 0.99998771, 0.9999908 , 0.99998575,\n",
       "       0.99994957, 0.99999997, 0.99999924, 0.99999908, 0.99996612,\n",
       "       0.99999948, 0.99999193, 0.99997837, 0.9999992 , 0.99999995,\n",
       "       0.99999728, 0.99999999, 0.99999968, 0.9999997 , 0.99995708,\n",
       "       0.99999977, 0.99999963, 0.9962676 , 0.99999975, 0.99999943,\n",
       "       0.99999956, 0.99999911, 0.99999994, 0.99947562, 0.999998  ,\n",
       "       0.99999943, 0.97774219, 0.99999282, 0.9999995 , 0.99999846,\n",
       "       0.99999889, 0.99999925, 0.99999956, 0.9999952 , 0.99999392,\n",
       "       0.99999958, 0.99999995, 0.99999135, 0.99999861, 0.99999846,\n",
       "       0.99999812, 0.99999921, 0.99999889, 0.99999979, 0.99999915,\n",
       "       0.99999969, 0.99999959, 0.99999981, 0.99999969, 0.9999615 ,\n",
       "       0.9999991 , 0.99999912, 0.99999999, 0.9999931 , 0.99998806,\n",
       "       0.99999659, 0.99999962, 0.99999442, 0.99999618, 0.99999733,\n",
       "       0.99999989, 0.99997688, 0.99999089, 0.99999981, 0.99999999,\n",
       "       0.99999935, 0.99999999, 0.99999971, 0.99999985, 0.9999942 ,\n",
       "       0.99999903, 0.99999977, 0.99999316, 0.99999999, 0.9999998 ,\n",
       "       0.99999992, 0.99999991, 0.9999969 , 0.99999816, 0.99999991,\n",
       "       0.99999141, 0.99999995, 0.99996211, 0.99999893, 0.99999929,\n",
       "       0.99999787, 0.99998852, 0.99999726])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the Percpetron class object to our features and outcome data\n",
    "prcpt.fit_model_predict(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
